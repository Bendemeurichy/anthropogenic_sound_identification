{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9450b809",
   "metadata": {},
   "source": [
    "# Label counting to determine dataset size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a537f1ec",
   "metadata": {},
   "source": [
    "## Label mapping from ontology to datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d78b50cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 22:47:17.523840: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10336def",
   "metadata": {},
   "source": [
    "Setting up embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a76d7ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"google/embeddinggemma-300m\")\n",
    "\n",
    "def embed_texts(texts)-> np.ndarray:\n",
    "    vectors = model.encode(\n",
    "        texts, normalize_embeddings=False\n",
    "    ).astype('float32')\n",
    "    # Normalize the vectors to unit length\n",
    "    vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "    \n",
    "    return vectors\n",
    "\n",
    "def build_index(texts: list[str]) -> faiss.IndexFlatIP:\n",
    "    vectors = embed_texts(texts)\n",
    "    dimension = vectors.shape[1]\n",
    "    \n",
    "    index = faiss.IndexFlatIP(dimension)#\n",
    "    \n",
    "    label_vectors = vectors.astype('float32')\n",
    "    index.add(label_vectors)\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f67fc1",
   "metadata": {},
   "source": [
    "Load in ontology labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "625bd2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['measurement vehicle noise',\n",
       " 'shout and scream',\n",
       " 'rooster',\n",
       " 'amplified music and electronic playback',\n",
       " 'laughter',\n",
       " 'boat',\n",
       " 'Acoustical Vehicle Alerting System',\n",
       " 'tram',\n",
       " 'explosion',\n",
       " 'motorcycle',\n",
       " 'bird call',\n",
       " 'bus',\n",
       " 'bell',\n",
       " 'sawing, ginding',\n",
       " 'dawn chorus',\n",
       " 'life instrumental music, few instruments',\n",
       " 'jackhammer, breaker',\n",
       " 'noise policy field sound classification',\n",
       " 'dog bark',\n",
       " 'vehicle horn',\n",
       " 'drone',\n",
       " 'bird whistle',\n",
       " 'roll',\n",
       " 'footsteps',\n",
       " 'crane, buldozer',\n",
       " 'impact',\n",
       " 'scrape',\n",
       " 'reverse beeper',\n",
       " 'drill',\n",
       " 'insect chorus',\n",
       " 'children playing',\n",
       " 'alarm',\n",
       " 'caugh',\n",
       " 'spraying water',\n",
       " 'buzzing bees and flies',\n",
       " 'siren',\n",
       " 'truck',\n",
       " 'plane',\n",
       " 'train',\n",
       " 'vocal music',\n",
       " 'horeshoes',\n",
       " 'aeolian tones',\n",
       " 'poultry',\n",
       " 'car',\n",
       " 'speech',\n",
       " 'songbird song',\n",
       " 'pile-driver',\n",
       " 'helicopter',\n",
       " 'chainsaw',\n",
       " 'hammer',\n",
       " 'machete',\n",
       " 'motor',\n",
       " 'siren',\n",
       " 'tractor',\n",
       " 'turbine',\n",
       " 'whistling',\n",
       " 'thunder',\n",
       " 'flowing water',\n",
       " 'rustling leaves',\n",
       " 'microphone wind noise',\n",
       " 'industry hum',\n",
       " 'crowd',\n",
       " 'electrical hum',\n",
       " 'cables and chains',\n",
       " 'fan, air conditioner, heat pump',\n",
       " 'rain',\n",
       " 'road traffic',\n",
       " 'breaking waves',\n",
       " 'falling water',\n",
       " 'pump']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdflib.namespace import OWL, RDFS\n",
    "import rdflib\n",
    "\n",
    "g = rdflib.Graph()\n",
    "g.parse(\"../../anthropogenic_ontology.ttl\", format=\"turtle\")\n",
    "\n",
    "BASE = (\"http://www.semanticweb.org/dbotteld/ontologies/2025/6/sound_ontology#\")\n",
    "\n",
    "labels = []\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT ?cls ?label\n",
    "WHERE {\n",
    "  ?cls a owl:Class .\n",
    "  FILTER NOT EXISTS { ?sub rdfs:subClassOf ?cls . }\n",
    "  OPTIONAL { ?cls rdfs:label ?label . }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "no_label_list = [\"AudioSet\"]\n",
    "\n",
    "for row in g.query(query, initNs={\"owl\": OWL, \"rdfs\": RDFS, \"base\": BASE}):\n",
    "    label = row.label if row.label else row.cls\n",
    "    if str(label) not in no_label_list:  \n",
    "      labels.append(str(label))\n",
    "\n",
    "label_vectors = embed_texts(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca7983",
   "metadata": {},
   "source": [
    "### Similarity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa3b40cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_dataframe(\n",
    "    query_labels: list[str],\n",
    "    dataset_labels: list[str],\n",
    "    top_k: int = 3\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a DataFrame with similarity scores between ontology labels and dataset labels.\n",
    "    \n",
    "    Args:\n",
    "        query_labels: List of ontology labels to query\n",
    "        dataset_labels: List of dataset labels to build the index from\n",
    "        top_k: Number of top similar labels to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: ontology_label, dataset_labels, dataset_indices, similarity_scores\n",
    "    \"\"\"\n",
    "    # Build index from dataset labels\n",
    "    dataset_vectors = embed_texts(dataset_labels)\n",
    "    dimension = dataset_vectors.shape[1]\n",
    "    index = faiss.IndexFlatIP(dimension)\n",
    "    index.add(dataset_vectors)\n",
    "    \n",
    "    mapping_data = []\n",
    "    \n",
    "    for ontology_label in query_labels:\n",
    "        # Embed and normalize the ontology label\n",
    "        query_vector = embed_texts([ontology_label])\n",
    "        \n",
    "        # Search for top-k similar dataset labels\n",
    "        scores, indices = index.search(query_vector, top_k)\n",
    "        \n",
    "        # Get matched labels and round scores\n",
    "        matched_labels = [dataset_labels[i] for i in indices[0]]\n",
    "        rounded_scores = [float(round(float(score), 4)) for score in scores[0]]\n",
    "        \n",
    "        mapping_data.append({\n",
    "            'ontology_label': ontology_label,\n",
    "            'dataset_labels': matched_labels,\n",
    "            'dataset_indices': indices.tolist()[0],\n",
    "            'similarity_scores': rounded_scores\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(mapping_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cfa031",
   "metadata": {},
   "source": [
    "## Class of interest 1: Plane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f346f8c7",
   "metadata": {},
   "source": [
    "### audioset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "904b6c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mid",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "display_name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "1a75a83d-89ac-4664-aa17-9a32003c9f5d",
       "rows": [
        [
         "0",
         "/g/11b630rrvh",
         "Kettle whistle"
        ],
        [
         "1",
         "/g/122z_qxw",
         "Firecracker"
        ],
        [
         "2",
         "/m/01280g",
         "Wild animals"
        ],
        [
         "3",
         "/m/012f08",
         "Motor vehicle (road)"
        ],
        [
         "4",
         "/m/012n7d",
         "Ambulance (siren)"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>display_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/g/11b630rrvh</td>\n",
       "      <td>Kettle whistle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/g/122z_qxw</td>\n",
       "      <td>Firecracker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/m/01280g</td>\n",
       "      <td>Wild animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/m/012f08</td>\n",
       "      <td>Motor vehicle (road)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/m/012n7d</td>\n",
       "      <td>Ambulance (siren)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mid          display_name\n",
       "0  /g/11b630rrvh        Kettle whistle\n",
       "1    /g/122z_qxw           Firecracker\n",
       "2      /m/01280g          Wild animals\n",
       "3      /m/012f08  Motor vehicle (road)\n",
       "4      /m/012n7d     Ambulance (siren)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid_to_label_map = pd.read_csv(\n",
    "    \"../../data/metadata/audioset/mid_to_display_name.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"mid\", \"display_name\"],\n",
    ")\n",
    "mid_to_label_dict = dict(zip(mid_to_label_map[\"mid\"], mid_to_label_map[\"display_name\"]))\n",
    "\n",
    "mid_to_label_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "402e3c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "segment_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start_time_seconds",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "end_time_seconds",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "a2dc717f-a168-479c-b3fe-6bd5dd7e5c05",
       "rows": [
        [
         "0",
         "b0RFKhbpFJA_30000",
         "0.0",
         "10.0",
         "Wind"
        ],
        [
         "1",
         "b0RFKhbpFJA_30000",
         "4.753",
         "5.72",
         "Male speech, man speaking"
        ],
        [
         "2",
         "b0RFKhbpFJA_30000",
         "0.0",
         "10.0",
         "Buzz"
        ],
        [
         "3",
         "b0RFKhbpFJA_30000",
         "6.899",
         "7.01",
         "Tick"
        ],
        [
         "4",
         "b0RFKhbpFJA_30000",
         "8.534",
         "9.156",
         "Wind noise (microphone)"
        ],
        [
         "5",
         "NQNTnl0zaqU_70000",
         "0.0",
         "0.103",
         "Whack, thwack"
        ],
        [
         "6",
         "NQNTnl0zaqU_70000",
         "0.233",
         "0.443",
         "Whack, thwack"
        ],
        [
         "7",
         "NQNTnl0zaqU_70000",
         "0.542",
         "0.785",
         "Whack, thwack"
        ],
        [
         "8",
         "NQNTnl0zaqU_70000",
         "0.94",
         "1.208",
         "Whack, thwack"
        ],
        [
         "9",
         "NQNTnl0zaqU_70000",
         "1.2",
         "2.183",
         "Cash register"
        ],
        [
         "10",
         "NQNTnl0zaqU_70000",
         "1.947",
         "4.246",
         "Power tool"
        ],
        [
         "11",
         "NQNTnl0zaqU_70000",
         "3.539",
         "5.464",
         "Sawing"
        ],
        [
         "12",
         "NQNTnl0zaqU_70000",
         "4.944",
         "6.951",
         "Train horn"
        ],
        [
         "13",
         "NQNTnl0zaqU_70000",
         "6.975",
         "7.869",
         "Sound effect"
        ],
        [
         "14",
         "NQNTnl0zaqU_70000",
         "7.999",
         "8.933",
         "Sound effect"
        ],
        [
         "15",
         "NQNTnl0zaqU_70000",
         "9.063",
         "10.0",
         "Sound effect"
        ],
        [
         "16",
         "4PPmyY_-YrA_30000",
         "0.0",
         "10.0",
         "Hair dryer"
        ],
        [
         "17",
         "4PPmyY_-YrA_30000",
         "7.983",
         "8.161",
         "Tick"
        ],
        [
         "18",
         "LvNUyQ3xuAQ_0",
         "0.596",
         "5.677",
         "Dial tone"
        ],
        [
         "19",
         "XMl9lI7mKsM_50000",
         "0.0",
         "1.246",
         "Male singing"
        ],
        [
         "20",
         "XMl9lI7mKsM_50000",
         "0.0",
         "10.0",
         "Music"
        ],
        [
         "21",
         "XMl9lI7mKsM_50000",
         "1.595",
         "1.851",
         "Male singing"
        ],
        [
         "22",
         "XMl9lI7mKsM_50000",
         "2.375",
         "2.91",
         "Shout"
        ],
        [
         "23",
         "XMl9lI7mKsM_50000",
         "5.437",
         "8.394",
         "Male singing"
        ],
        [
         "24",
         "O35jXasNYxc_30000",
         "0.0",
         "0.381",
         "Human sounds"
        ],
        [
         "25",
         "O35jXasNYxc_30000",
         "0.0",
         "10.0",
         "Background noise"
        ],
        [
         "26",
         "O35jXasNYxc_30000",
         "0.733",
         "1.578",
         "Cough"
        ],
        [
         "27",
         "O35jXasNYxc_30000",
         "1.683",
         "2.094",
         "Cough"
        ],
        [
         "28",
         "O35jXasNYxc_30000",
         "2.191",
         "2.565",
         "Cough"
        ],
        [
         "29",
         "O35jXasNYxc_30000",
         "2.708",
         "3.134",
         "Cough"
        ],
        [
         "30",
         "O35jXasNYxc_30000",
         "3.762",
         "4.024",
         "Cough"
        ],
        [
         "31",
         "O35jXasNYxc_30000",
         "4.084",
         "4.892",
         "Human sounds"
        ],
        [
         "32",
         "O35jXasNYxc_30000",
         "5.37",
         "6.2",
         "Cough"
        ],
        [
         "33",
         "O35jXasNYxc_30000",
         "6.313",
         "6.859",
         "Cough"
        ],
        [
         "34",
         "O35jXasNYxc_30000",
         "7.076",
         "7.322",
         "Cough"
        ],
        [
         "35",
         "O35jXasNYxc_30000",
         "7.307",
         "7.921",
         "Human sounds"
        ],
        [
         "36",
         "O35jXasNYxc_30000",
         "8.205",
         "9.596",
         "Cough"
        ],
        [
         "37",
         "O35jXasNYxc_30000",
         "9.663",
         "10.0",
         "Human sounds"
        ],
        [
         "38",
         "s451ci8Fric_30000",
         "0.0",
         "10.0",
         "Fire alarm"
        ],
        [
         "39",
         "s451ci8Fric_30000",
         "0.0",
         "10.0",
         "Mechanisms"
        ],
        [
         "40",
         "s451ci8Fric_30000",
         "0.363",
         "1.744",
         "Speech synthesizer"
        ],
        [
         "41",
         "cUAe_N9oODs_0",
         "0.148",
         "2.329",
         "Howl"
        ],
        [
         "42",
         "cUAe_N9oODs_0",
         "0.16",
         "10.0",
         "Background noise"
        ],
        [
         "43",
         "cUAe_N9oODs_0",
         "0.363",
         "0.883",
         "Female speech, woman speaking"
        ],
        [
         "44",
         "cUAe_N9oODs_0",
         "0.964",
         "1.135",
         "Generic impact sounds"
        ],
        [
         "45",
         "cUAe_N9oODs_0",
         "1.419",
         "1.793",
         "Bark"
        ],
        [
         "46",
         "cUAe_N9oODs_0",
         "2.556",
         "2.816",
         "Dog"
        ],
        [
         "47",
         "cUAe_N9oODs_0",
         "2.979",
         "3.539",
         "Laughter"
        ],
        [
         "48",
         "cUAe_N9oODs_0",
         "3.255",
         "4.847",
         "Howl"
        ],
        [
         "49",
         "cUAe_N9oODs_0",
         "3.645",
         "3.775",
         "Generic impact sounds"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 934821
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>start_time_seconds</th>\n",
       "      <th>end_time_seconds</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b0RFKhbpFJA_30000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>Wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b0RFKhbpFJA_30000</td>\n",
       "      <td>4.753</td>\n",
       "      <td>5.720</td>\n",
       "      <td>Male speech, man speaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b0RFKhbpFJA_30000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>Buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b0RFKhbpFJA_30000</td>\n",
       "      <td>6.899</td>\n",
       "      <td>7.010</td>\n",
       "      <td>Tick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b0RFKhbpFJA_30000</td>\n",
       "      <td>8.534</td>\n",
       "      <td>9.156</td>\n",
       "      <td>Wind noise (microphone)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934816</th>\n",
       "      <td>cq-vfngNXMc_70000</td>\n",
       "      <td>7.836</td>\n",
       "      <td>8.015</td>\n",
       "      <td>Tick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934817</th>\n",
       "      <td>cq-vfngNXMc_70000</td>\n",
       "      <td>8.226</td>\n",
       "      <td>8.511</td>\n",
       "      <td>Generic impact sounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934818</th>\n",
       "      <td>cq-vfngNXMc_70000</td>\n",
       "      <td>8.503</td>\n",
       "      <td>8.868</td>\n",
       "      <td>Male speech, man speaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934819</th>\n",
       "      <td>cq-vfngNXMc_70000</td>\n",
       "      <td>9.217</td>\n",
       "      <td>9.624</td>\n",
       "      <td>Generic impact sounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934820</th>\n",
       "      <td>cq-vfngNXMc_70000</td>\n",
       "      <td>9.778</td>\n",
       "      <td>10.000</td>\n",
       "      <td>Generic impact sounds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>934821 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               segment_id  start_time_seconds  end_time_seconds  \\\n",
       "0       b0RFKhbpFJA_30000               0.000            10.000   \n",
       "1       b0RFKhbpFJA_30000               4.753             5.720   \n",
       "2       b0RFKhbpFJA_30000               0.000            10.000   \n",
       "3       b0RFKhbpFJA_30000               6.899             7.010   \n",
       "4       b0RFKhbpFJA_30000               8.534             9.156   \n",
       "...                   ...                 ...               ...   \n",
       "934816  cq-vfngNXMc_70000               7.836             8.015   \n",
       "934817  cq-vfngNXMc_70000               8.226             8.511   \n",
       "934818  cq-vfngNXMc_70000               8.503             8.868   \n",
       "934819  cq-vfngNXMc_70000               9.217             9.624   \n",
       "934820  cq-vfngNXMc_70000               9.778            10.000   \n",
       "\n",
       "                            label  \n",
       "0                            Wind  \n",
       "1       Male speech, man speaking  \n",
       "2                            Buzz  \n",
       "3                            Tick  \n",
       "4         Wind noise (microphone)  \n",
       "...                           ...  \n",
       "934816                       Tick  \n",
       "934817      Generic impact sounds  \n",
       "934818  Male speech, man speaking  \n",
       "934819      Generic impact sounds  \n",
       "934820      Generic impact sounds  \n",
       "\n",
       "[934821 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audioset_labels = pd.read_csv(\n",
    "    \"../../data/metadata/audioset/audioset_train_strong.tsv\", sep=\"\\t\"\n",
    ")\n",
    "audioset_labels['label'] = audioset_labels['label'].apply(lambda x: mid_to_label_dict[x])\n",
    "audioset_labels.head()\n",
    "audioset_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe48a21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ontology_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset_labels",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "dataset_indices",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "similarity_scores",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "887cf317-3263-4b39-825f-20e72ad40df9",
       "rows": [
        [
         "0",
         "measurement vehicle noise",
         "['Traffic noise, roadway noise', 'Environmental noise', 'Noise']",
         "[131, 39, 80]",
         "[0.6874, 0.6822, 0.6782]"
        ],
        [
         "1",
         "shout and scream",
         "['Screaming', 'Shout', 'Yell']",
         "[138, 15, 406]",
         "[0.8618, 0.8449, 0.8105]"
        ],
        [
         "2",
         "rooster",
         "['Chicken, rooster', 'Cluck', 'Rattle']",
         "[165, 149, 182]",
         "[0.7468, 0.741, 0.7265]"
        ],
        [
         "3",
         "amplified music and electronic playback",
         "['Music', 'Electronic tuner', 'Sound reproduction']",
         "[14, 361, 438]",
         "[0.6163, 0.5818, 0.5673]"
        ],
        [
         "4",
         "laughter",
         "['Laughter', 'Giggle', 'Belly laugh']",
         "[27, 49, 29]",
         "[0.9721, 0.9079, 0.8285]"
        ],
        [
         "5",
         "boat",
         "['Motorboat, speedboat', 'Boat, Water vehicle', 'Sailboat, sailing ship']",
         "[92, 232, 283]",
         "[0.8237, 0.8164, 0.7698]"
        ],
        [
         "6",
         "Acoustical Vehicle Alerting System",
         "['Car alarm', 'Civil defense siren', 'Vehicle']",
         "[61, 265, 170]",
         "[0.6588, 0.6265, 0.6029]"
        ],
        [
         "7",
         "tram",
         "['Train', 'Bus', 'Rail transport']",
         "[73, 245, 368]",
         "[0.7447, 0.6658, 0.6616]"
        ],
        [
         "8",
         "explosion",
         "['Explosion', 'Eruption', 'Boom']",
         "[110, 270, 277]",
         "[0.9341, 0.781, 0.699]"
        ],
        [
         "9",
         "motorcycle",
         "['Motorcycle', 'Engine', 'Vehicle']",
         "[142, 189, 170]",
         "[0.9859, 0.7756, 0.7565]"
        ],
        [
         "10",
         "bird call",
         "['Bird vocalization, bird call, bird song', 'Bird', 'Dial tone']",
         "[40, 43, 12]",
         "[0.8047, 0.7799, 0.733]"
        ],
        [
         "11",
         "bus",
         "['Bus', 'Vehicle', 'Buzz']",
         "[245, 170, 2]",
         "[0.9897, 0.6788, 0.6528]"
        ],
        [
         "12",
         "bell",
         "['Bell', 'Church bell', 'Doorbell']",
         "[69, 147, 315]",
         "[0.9667, 0.834, 0.8335]"
        ],
        [
         "13",
         "sawing, ginding",
         "['Sawing', 'Sanding', 'Power saw, circular saw, table saw']",
         "[8, 287, 339]",
         "[0.8117, 0.6688, 0.6647]"
        ],
        [
         "14",
         "dawn chorus",
         "['Choir', 'Foghorn', 'Chant']",
         "[200, 111, 343]",
         "[0.7146, 0.6759, 0.6667]"
        ],
        [
         "15",
         "life instrumental music, few instruments",
         "['Music', 'Choir', 'Wolf-whistling']",
         "[14, 200, 407]",
         "[0.6352, 0.5264, 0.5198]"
        ],
        [
         "16",
         "jackhammer, breaker",
         "['Jackhammer', 'Hammer', 'Crockery breaking and smashing']",
         "[324, 327, 385]",
         "[0.8436, 0.759, 0.6886]"
        ],
        [
         "17",
         "noise policy field sound classification",
         "['Noise', 'Environmental noise', 'Background noise']",
         "[80, 39, 17]",
         "[0.6706, 0.6456, 0.6288]"
        ],
        [
         "18",
         "dog bark",
         "['Bark', 'Dog', 'Growling']",
         "[25, 26, 53]",
         "[0.8868, 0.8263, 0.7381]"
        ],
        [
         "19",
         "vehicle horn",
         "['Vehicle horn, car horn, honking, toot', 'Train horn', 'Air horn, truck horn']",
         "[244, 9, 229]",
         "[0.8197, 0.7954, 0.767]"
        ],
        [
         "20",
         "drone",
         "['Electric rotor drone, quadcopter', 'Helicopter', 'Drill']",
         "[301, 275, 213]",
         "[0.7596, 0.7172, 0.6903]"
        ],
        [
         "21",
         "bird whistle",
         "['Whistle', 'Steam whistle', 'Whistling']",
         "[203, 249, 108]",
         "[0.8381, 0.8171, 0.7972]"
        ],
        [
         "22",
         "roll",
         "['Roll', 'Whir', 'Drill']",
         "[393, 236, 213]",
         "[0.9857, 0.7027, 0.7027]"
        ],
        [
         "23",
         "footsteps",
         "['Walk, footsteps', 'Stairs', 'Bark']",
         "[99, 411, 25]",
         "[0.8479, 0.6645, 0.6294]"
        ],
        [
         "24",
         "crane, buldozer",
         "['Lawn mower', 'Bicycle, tricycle', \"Dental drill, dentist's drill\"]",
         "[167, 132, 367]",
         "[0.6328, 0.6318, 0.6218]"
        ],
        [
         "25",
         "impact",
         "['Hammer', 'Jackhammer', 'Generic impact sounds']",
         "[327, 324, 24]",
         "[0.6229, 0.6221, 0.6191]"
        ],
        [
         "26",
         "scrape",
         "['Scrape', 'Scratch', 'Crack']",
         "[51, 306, 391]",
         "[0.9019, 0.762, 0.6888]"
        ],
        [
         "27",
         "reverse beeper",
         "['Reversing beeps', 'Reverberation', 'Ringing tone, ringback tone']",
         "[169, 369, 430]",
         "[0.9092, 0.6749, 0.6536]"
        ],
        [
         "28",
         "drill",
         "['Drill', \"Dental drill, dentist's drill\", 'Power tool']",
         "[213, 367, 7]",
         "[0.9406, 0.7589, 0.7514]"
        ],
        [
         "29",
         "insect chorus",
         "['Insect', 'Choir', 'Chant']",
         "[72, 200, 343]",
         "[0.7785, 0.6542, 0.6319]"
        ],
        [
         "30",
         "children playing",
         "['Children playing', 'Children shouting', 'Bouncing']",
         "[353, 354, 308]",
         "[0.9962, 0.6752, 0.6468]"
        ],
        [
         "31",
         "alarm",
         "['Alarm', 'Alarm clock', 'Car alarm']",
         "[75, 101, 61]",
         "[0.9908, 0.9221, 0.867]"
        ],
        [
         "32",
         "caugh",
         "['Caw', 'Sigh', 'Gargling']",
         "[74, 302, 389]",
         "[0.8241, 0.7805, 0.7704]"
        ],
        [
         "33",
         "spraying water",
         "['Spray', 'Water', 'Water tap, faucet']",
         "[107, 65, 290]",
         "[0.7854, 0.7646, 0.6994]"
        ],
        [
         "34",
         "buzzing bees and flies",
         "['Bee, wasp, etc.', 'Insect', 'Fly, housefly']",
         "[231, 72, 377]",
         "[0.7639, 0.6369, 0.6165]"
        ],
        [
         "35",
         "siren",
         "['Siren', 'Ambulance (siren)', 'Police car (siren)']",
         "[208, 171, 155]",
         "[0.9222, 0.6966, 0.682]"
        ],
        [
         "36",
         "truck",
         "['Truck', 'Vehicle', 'Engine']",
         "[97, 170, 189]",
         "[0.9872, 0.7851, 0.7234]"
        ],
        [
         "37",
         "plane",
         "['Aircraft', 'Fixed-wing aircraft, airplane', 'Aircraft engine']",
         "[210, 233, 159]",
         "[0.8858, 0.7779, 0.758]"
        ],
        [
         "38",
         "train",
         "['Train', 'Train whistle', 'Train horn']",
         "[73, 266, 9]",
         "[0.9878, 0.8066, 0.8045]"
        ],
        [
         "39",
         "vocal music",
         "['Music', 'Singing', 'Yodeling']",
         "[14, 137, 207]",
         "[0.8192, 0.8026, 0.7653]"
        ],
        [
         "40",
         "horeshoes",
         "['Ship', 'Hoot', 'Slosh']",
         "[77, 342, 282]",
         "[0.6522, 0.6091, 0.6082]"
        ],
        [
         "41",
         "aeolian tones",
         "['Respiratory sounds', 'Human sounds', 'Chirp tone']",
         "[409, 16, 370]",
         "[0.6839, 0.6727, 0.6676]"
        ],
        [
         "42",
         "poultry",
         "['Fowl', 'Chicken, rooster', 'Cluck']",
         "[348, 165, 149]",
         "[0.8055, 0.7583, 0.7381]"
        ],
        [
         "43",
         "car",
         "['Car', 'Vehicle', 'Race car, auto racing']",
         "[59, 170, 296]",
         "[0.9875, 0.8471, 0.7675]"
        ],
        [
         "44",
         "speech",
         "['Speech', 'Speech synthesizer', 'Child speech, kid speaking']",
         "[36, 21, 33]",
         "[0.9856, 0.7938, 0.7879]"
        ],
        [
         "45",
         "songbird song",
         "['Bird', 'Singing', 'Bird vocalization, bird call, bird song']",
         "[43, 137, 40]",
         "[0.8134, 0.7093, 0.7014]"
        ],
        [
         "46",
         "pile-driver",
         "['Drill', 'Pulleys', 'Truck']",
         "[213, 319, 97]",
         "[0.6678, 0.6512, 0.6256]"
        ],
        [
         "47",
         "helicopter",
         "['Helicopter', 'Aircraft', 'Motorcycle']",
         "[275, 210, 142]",
         "[0.9429, 0.732, 0.6851]"
        ],
        [
         "48",
         "chainsaw",
         "['Chainsaw', 'Sawing', 'Chain']",
         "[175, 8, 440]",
         "[0.9241, 0.7755, 0.7531]"
        ],
        [
         "49",
         "hammer",
         "['Hammer', 'Jackhammer', 'Power tool']",
         "[327, 324, 7]",
         "[0.9605, 0.9111, 0.7437]"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 70
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ontology_label</th>\n",
       "      <th>dataset_labels</th>\n",
       "      <th>dataset_indices</th>\n",
       "      <th>similarity_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>measurement vehicle noise</td>\n",
       "      <td>[Traffic noise, roadway noise, Environmental n...</td>\n",
       "      <td>[131, 39, 80]</td>\n",
       "      <td>[0.6874, 0.6822, 0.6782]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shout and scream</td>\n",
       "      <td>[Screaming, Shout, Yell]</td>\n",
       "      <td>[138, 15, 406]</td>\n",
       "      <td>[0.8618, 0.8449, 0.8105]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rooster</td>\n",
       "      <td>[Chicken, rooster, Cluck, Rattle]</td>\n",
       "      <td>[165, 149, 182]</td>\n",
       "      <td>[0.7468, 0.741, 0.7265]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amplified music and electronic playback</td>\n",
       "      <td>[Music, Electronic tuner, Sound reproduction]</td>\n",
       "      <td>[14, 361, 438]</td>\n",
       "      <td>[0.6163, 0.5818, 0.5673]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>laughter</td>\n",
       "      <td>[Laughter, Giggle, Belly laugh]</td>\n",
       "      <td>[27, 49, 29]</td>\n",
       "      <td>[0.9721, 0.9079, 0.8285]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>rain</td>\n",
       "      <td>[Rain, Rain on surface, Raindrop]</td>\n",
       "      <td>[70, 237, 371]</td>\n",
       "      <td>[0.9536, 0.785, 0.7682]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>road traffic</td>\n",
       "      <td>[Traffic noise, roadway noise, Motor vehicle (...</td>\n",
       "      <td>[131, 57, 170]</td>\n",
       "      <td>[0.7944, 0.7838, 0.6875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>breaking waves</td>\n",
       "      <td>[Waves, surf, Breaking, Ocean]</td>\n",
       "      <td>[198, 71, 76]</td>\n",
       "      <td>[0.8071, 0.7745, 0.7326]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>falling water</td>\n",
       "      <td>[Waterfall, Water, Raindrop]</td>\n",
       "      <td>[206, 65, 371]</td>\n",
       "      <td>[0.8236, 0.6955, 0.6695]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>pump</td>\n",
       "      <td>[Pump (liquid), Pulleys, Jackhammer]</td>\n",
       "      <td>[350, 319, 324]</td>\n",
       "      <td>[0.8346, 0.7203, 0.7135]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ontology_label  \\\n",
       "0                 measurement vehicle noise   \n",
       "1                          shout and scream   \n",
       "2                                   rooster   \n",
       "3   amplified music and electronic playback   \n",
       "4                                  laughter   \n",
       "..                                      ...   \n",
       "65                                     rain   \n",
       "66                             road traffic   \n",
       "67                           breaking waves   \n",
       "68                            falling water   \n",
       "69                                     pump   \n",
       "\n",
       "                                       dataset_labels  dataset_indices  \\\n",
       "0   [Traffic noise, roadway noise, Environmental n...    [131, 39, 80]   \n",
       "1                            [Screaming, Shout, Yell]   [138, 15, 406]   \n",
       "2                   [Chicken, rooster, Cluck, Rattle]  [165, 149, 182]   \n",
       "3       [Music, Electronic tuner, Sound reproduction]   [14, 361, 438]   \n",
       "4                     [Laughter, Giggle, Belly laugh]     [27, 49, 29]   \n",
       "..                                                ...              ...   \n",
       "65                  [Rain, Rain on surface, Raindrop]   [70, 237, 371]   \n",
       "66  [Traffic noise, roadway noise, Motor vehicle (...   [131, 57, 170]   \n",
       "67                     [Waves, surf, Breaking, Ocean]    [198, 71, 76]   \n",
       "68                       [Waterfall, Water, Raindrop]   [206, 65, 371]   \n",
       "69               [Pump (liquid), Pulleys, Jackhammer]  [350, 319, 324]   \n",
       "\n",
       "           similarity_scores  \n",
       "0   [0.6874, 0.6822, 0.6782]  \n",
       "1   [0.8618, 0.8449, 0.8105]  \n",
       "2    [0.7468, 0.741, 0.7265]  \n",
       "3   [0.6163, 0.5818, 0.5673]  \n",
       "4   [0.9721, 0.9079, 0.8285]  \n",
       "..                       ...  \n",
       "65   [0.9536, 0.785, 0.7682]  \n",
       "66  [0.7944, 0.7838, 0.6875]  \n",
       "67  [0.8071, 0.7745, 0.7326]  \n",
       "68  [0.8236, 0.6955, 0.6695]  \n",
       "69  [0.8346, 0.7203, 0.7135]  \n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audioset_label_list = audioset_labels['label'].unique().tolist()\n",
    "\n",
    "similarity_df = build_similarity_dataframe(\n",
    "    query_labels=labels,\n",
    "    dataset_labels=audioset_label_list,\n",
    "    top_k=3\n",
    ")\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a605720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Environmental noise',\n",
       " 'Motor vehicle (road)',\n",
       " 'Bird',\n",
       " 'Boat, Water vehicle',\n",
       " 'Bee, wasp, etc.',\n",
       " 'Pulleys',\n",
       " 'Whistling',\n",
       " 'Human sounds',\n",
       " 'Waves, surf',\n",
       " 'Fowl',\n",
       " 'Boom',\n",
       " 'Water',\n",
       " 'Pump (liquid)',\n",
       " 'Whistle',\n",
       " 'Hum',\n",
       " 'Jackhammer',\n",
       " 'Power tool',\n",
       " 'Speech',\n",
       " 'Hammer',\n",
       " 'Cluck',\n",
       " 'Dog',\n",
       " 'Power saw, circular saw, table saw',\n",
       " 'Chant',\n",
       " 'Electronic tuner',\n",
       " 'Car',\n",
       " 'Cheering',\n",
       " 'Traffic noise, roadway noise',\n",
       " 'Chicken, rooster',\n",
       " 'Yodeling',\n",
       " 'Ship',\n",
       " 'Ocean',\n",
       " 'Noise',\n",
       " 'Growling',\n",
       " 'Breaking',\n",
       " 'Vehicle horn, car horn, honking, toot',\n",
       " 'Sawing',\n",
       " 'Vehicle',\n",
       " 'Engine',\n",
       " 'Siren',\n",
       " 'Crow',\n",
       " 'Choir',\n",
       " 'Chainsaw',\n",
       " 'Child speech, kid speaking',\n",
       " 'Ringing tone, ringback tone',\n",
       " 'Alarm',\n",
       " 'Lawn mower',\n",
       " 'Bicycle, tricycle',\n",
       " 'Truck',\n",
       " 'Fly, housefly',\n",
       " 'Knife',\n",
       " 'Chain',\n",
       " 'Buzz',\n",
       " 'Walk, footsteps',\n",
       " 'Raindrop',\n",
       " 'Alarm clock',\n",
       " 'Helicopter',\n",
       " 'Stream, river',\n",
       " 'Screaming',\n",
       " 'Church bell',\n",
       " 'Rattle',\n",
       " 'Doorbell',\n",
       " 'Chop',\n",
       " 'Rail transport',\n",
       " 'Race car, auto racing',\n",
       " 'Water tap, faucet',\n",
       " 'Paper rustling',\n",
       " 'Crockery breaking and smashing',\n",
       " 'Generic impact sounds',\n",
       " 'Bird vocalization, bird call, bird song',\n",
       " 'Hoot',\n",
       " 'Motorcycle',\n",
       " 'Belly laugh',\n",
       " 'Roll',\n",
       " 'Whir',\n",
       " 'Waterfall',\n",
       " 'Rustle',\n",
       " 'Spray',\n",
       " 'Foghorn',\n",
       " 'Mechanical fan',\n",
       " 'Aircraft',\n",
       " 'Wind',\n",
       " 'Thunderstorm',\n",
       " 'Train',\n",
       " 'Fixed-wing aircraft, airplane',\n",
       " 'Respiratory sounds',\n",
       " 'Bus',\n",
       " 'Children playing',\n",
       " 'Sanding',\n",
       " 'Train horn',\n",
       " 'Propeller, airscrew',\n",
       " 'Drill',\n",
       " 'Rain on surface',\n",
       " 'Tools',\n",
       " 'Crowd',\n",
       " 'Yell',\n",
       " 'Electric rotor drone, quadcopter',\n",
       " 'Air horn, truck horn',\n",
       " 'Police car (siren)',\n",
       " 'Ambulance (siren)',\n",
       " 'Laughter',\n",
       " 'Reversing beeps',\n",
       " 'Scrape',\n",
       " 'Sound reproduction',\n",
       " 'Insect',\n",
       " 'Singing',\n",
       " 'Wolf-whistling',\n",
       " 'Steam whistle',\n",
       " 'Stairs',\n",
       " 'Bouncing',\n",
       " 'Fusillade',\n",
       " 'Giggle',\n",
       " 'Train whistle',\n",
       " 'Bell',\n",
       " \"Dental drill, dentist's drill\",\n",
       " 'Dial tone',\n",
       " 'Car alarm',\n",
       " 'Air conditioning',\n",
       " 'Crack',\n",
       " 'Wind noise (microphone)',\n",
       " 'Gargling',\n",
       " 'Civil defense siren',\n",
       " 'Bark',\n",
       " 'Rain',\n",
       " 'Motorboat, speedboat',\n",
       " 'Sailboat, sailing ship',\n",
       " 'Explosion',\n",
       " 'Reverberation',\n",
       " 'Microphone',\n",
       " 'Scratch',\n",
       " 'Music',\n",
       " 'Caw',\n",
       " 'Speech synthesizer',\n",
       " 'Background noise',\n",
       " 'Thunder',\n",
       " 'Mains hum',\n",
       " 'Aircraft engine',\n",
       " 'Shout',\n",
       " 'Children shouting',\n",
       " 'Chirp tone',\n",
       " 'Sigh',\n",
       " 'Eruption',\n",
       " 'Slosh',\n",
       " 'Humming']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list all audioset labels found for similarity_df\n",
    "all_found_labels = set()\n",
    "for label in similarity_df['dataset_labels']:\n",
    "    all_found_labels.update(label)\n",
    "list(all_found_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340c60c3",
   "metadata": {},
   "source": [
    "#### count all labels similar to \"Plane\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54fd872",
   "metadata": {},
   "source": [
    "Labels most similar to \"plane\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6470ea3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aircraft', 'Fixed-wing aircraft, airplane', 'Aircraft engine']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planes = similarity_df[similarity_df['ontology_label'] == 'plane']['dataset_labels'].values[0]\n",
    "planes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08eb2dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_498050/2475481132.py:1: DtypeWarning: Columns (1,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  strong_audioset_labels_train = pd.read_csv(\"../../data/metadata/audioset/audioset_train_strong.tsv\", sep=\"\\t\",header=None,names=[\"filename\", \"start_time\", \"end_time\", \"label\",\"split\", \"caption\"])\n",
      "/tmp/ipykernel_498050/2475481132.py:2: DtypeWarning: Columns (1,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  strong_audioset_labels_eval = pd.read_csv(\"../../data/metadata/audioset/audioset_eval_strong.tsv\", sep=\"\\t\",header=None,names=[\"filename\", \"start_time\", \"end_time\", \"label\", \"split\", \"caption\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1074361, 6),\n",
       "             filename          start_time          end_time       label  split  \\\n",
       " 0         segment_id  start_time_seconds  end_time_seconds       label  train   \n",
       " 1  b0RFKhbpFJA_30000               0.000            10.000  /m/03m9d0z  train   \n",
       " 2  b0RFKhbpFJA_30000               4.753             5.720   /m/05zppz  train   \n",
       " 3  b0RFKhbpFJA_30000               0.000            10.000  /m/07pjwq1  train   \n",
       " 4  b0RFKhbpFJA_30000               6.899             7.010  /m/07qjznt  train   \n",
       " \n",
       "    caption  \n",
       " 0      NaN  \n",
       " 1      NaN  \n",
       " 2      NaN  \n",
       " 3      NaN  \n",
       " 4      NaN  )"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_audioset_labels_train = pd.read_csv(\"../../data/metadata/audioset/audioset_train_strong.tsv\", sep=\"\\t\",header=None,names=[\"filename\", \"start_time\", \"end_time\", \"label\",\"split\", \"caption\"])\n",
    "strong_audioset_labels_eval = pd.read_csv(\"../../data/metadata/audioset/audioset_eval_strong.tsv\", sep=\"\\t\",header=None,names=[\"filename\", \"start_time\", \"end_time\", \"label\", \"split\", \"caption\"])\n",
    "\n",
    "# Merge the two dataframes into one, keeping source split info and resetting the index\n",
    "strong_audioset_labels = pd.concat(\n",
    "    [\n",
    "        strong_audioset_labels_train.assign(split=\"train\"),\n",
    "        strong_audioset_labels_eval.assign(split=\"eval\"),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# quick check\n",
    "strong_audioset_labels.shape, strong_audioset_labels.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bee1d54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "end_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "caption",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "41513a1c-5879-416b-a73b-271bea3beaee",
       "rows": [
        [
         "0",
         "segment_id",
         "start_time_seconds",
         "end_time_seconds",
         "label",
         "train",
         null
        ],
        [
         "1",
         "b0RFKhbpFJA_30000",
         "0.000",
         "10.000",
         "Wind",
         "train",
         null
        ],
        [
         "2",
         "b0RFKhbpFJA_30000",
         "4.753",
         "5.720",
         "Male speech, man speaking",
         "train",
         null
        ],
        [
         "3",
         "b0RFKhbpFJA_30000",
         "0.000",
         "10.000",
         "Buzz",
         "train",
         null
        ],
        [
         "4",
         "b0RFKhbpFJA_30000",
         "6.899",
         "7.010",
         "Tick",
         "train",
         null
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>segment_id</td>\n",
       "      <td>start_time_seconds</td>\n",
       "      <td>end_time_seconds</td>\n",
       "      <td>label</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b0RFKhbpFJA_30000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>Wind</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b0RFKhbpFJA_30000</td>\n",
       "      <td>4.753</td>\n",
       "      <td>5.720</td>\n",
       "      <td>Male speech, man speaking</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b0RFKhbpFJA_30000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b0RFKhbpFJA_30000</td>\n",
       "      <td>6.899</td>\n",
       "      <td>7.010</td>\n",
       "      <td>Tick</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename          start_time          end_time  \\\n",
       "0         segment_id  start_time_seconds  end_time_seconds   \n",
       "1  b0RFKhbpFJA_30000               0.000            10.000   \n",
       "2  b0RFKhbpFJA_30000               4.753             5.720   \n",
       "3  b0RFKhbpFJA_30000               0.000            10.000   \n",
       "4  b0RFKhbpFJA_30000               6.899             7.010   \n",
       "\n",
       "                       label  split  caption  \n",
       "0                      label  train      NaN  \n",
       "1                       Wind  train      NaN  \n",
       "2  Male speech, man speaking  train      NaN  \n",
       "3                       Buzz  train      NaN  \n",
       "4                       Tick  train      NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the MID codes in 'label' with display names, keeping original MID if no mapping exists\n",
    "strong_audioset_labels['label'] = strong_audioset_labels['label'].map(mid_to_label_dict).fillna(strong_audioset_labels['label'])\n",
    "strong_audioset_labels.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1b059a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{False: 1073249, True: 1112}\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "eval",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "train",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "258f0c21-4b3d-43b2-8e9e-a32ffbef09cd",
       "rows": [
        [
         "Aircraft",
         "84",
         "355"
        ],
        [
         "Aircraft engine",
         "87",
         "290"
        ],
        [
         "Fixed-wing aircraft, airplane",
         "53",
         "243"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>split</th>\n",
       "      <th>eval</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aircraft</th>\n",
       "      <td>84</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aircraft engine</th>\n",
       "      <td>87</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fixed-wing aircraft, airplane</th>\n",
       "      <td>53</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "split                          eval  train\n",
       "label                                     \n",
       "Aircraft                         84    355\n",
       "Aircraft engine                  87    290\n",
       "Fixed-wing aircraft, airplane    53    243"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count exact matches for each plane-related label\n",
    "plane_counts = strong_audioset_labels['label'].isin(planes).value_counts().to_dict()\n",
    "print(plane_counts)\n",
    "\n",
    "# Also show counts broken down by split (train / eval)\n",
    "strong_audioset_labels[strong_audioset_labels['label'].isin(planes)].groupby(['label', 'split']).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf075a6",
   "metadata": {},
   "source": [
    "### urban_sound_8k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3631c0",
   "metadata": {},
   "source": [
    "(no airplane sounds in this dataset, contains only 10 classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c4b89a",
   "metadata": {},
   "source": [
    "### Esc-50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d7563d",
   "metadata": {},
   "source": [
    "Load in labels from ESC-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51dc2b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "esc10",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "src_file",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "take",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "bb4de781-d2ad-4d11-bc9d-47d77ffccb6d",
       "rows": [
        [
         "0",
         "1-100032-A-0.wav",
         "1",
         "0",
         "dog",
         "True",
         "100032",
         "A"
        ],
        [
         "1",
         "1-100038-A-14.wav",
         "1",
         "14",
         "chirping_birds",
         "False",
         "100038",
         "A"
        ],
        [
         "2",
         "1-100210-A-36.wav",
         "1",
         "36",
         "vacuum_cleaner",
         "False",
         "100210",
         "A"
        ],
        [
         "3",
         "1-100210-B-36.wav",
         "1",
         "36",
         "vacuum_cleaner",
         "False",
         "100210",
         "B"
        ],
        [
         "4",
         "1-101296-A-19.wav",
         "1",
         "19",
         "thunderstorm",
         "False",
         "101296",
         "A"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>esc10</th>\n",
       "      <th>src_file</th>\n",
       "      <th>take</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-100032-A-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>100032</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-100038-A-14.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>chirping_birds</td>\n",
       "      <td>False</td>\n",
       "      <td>100038</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-100210-A-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-100210-B-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-101296-A-19.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>False</td>\n",
       "      <td>101296</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  fold  target        category  esc10  src_file take\n",
       "0   1-100032-A-0.wav     1       0             dog   True    100032    A\n",
       "1  1-100038-A-14.wav     1      14  chirping_birds  False    100038    A\n",
       "2  1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A\n",
       "3  1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B\n",
       "4  1-101296-A-19.wav     1      19    thunderstorm  False    101296    A"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esc50_labels = pd.read_csv(\"../../data/metadata/esc50/esc50.csv\")\n",
    "esc50_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1530816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog',\n",
       " 'chirping_birds',\n",
       " 'vacuum_cleaner',\n",
       " 'thunderstorm',\n",
       " 'door_wood_knock',\n",
       " 'can_opening',\n",
       " 'crow',\n",
       " 'clapping',\n",
       " 'fireworks',\n",
       " 'chainsaw',\n",
       " 'airplane',\n",
       " 'mouse_click',\n",
       " 'pouring_water',\n",
       " 'train',\n",
       " 'sheep',\n",
       " 'water_drops',\n",
       " 'church_bells',\n",
       " 'clock_alarm',\n",
       " 'keyboard_typing',\n",
       " 'wind',\n",
       " 'footsteps',\n",
       " 'frog',\n",
       " 'cow',\n",
       " 'brushing_teeth',\n",
       " 'car_horn',\n",
       " 'crackling_fire',\n",
       " 'helicopter',\n",
       " 'drinking_sipping',\n",
       " 'rain',\n",
       " 'insects',\n",
       " 'laughing',\n",
       " 'hen',\n",
       " 'engine',\n",
       " 'breathing',\n",
       " 'crying_baby',\n",
       " 'hand_saw',\n",
       " 'coughing',\n",
       " 'glass_breaking',\n",
       " 'snoring',\n",
       " 'toilet_flush',\n",
       " 'pig',\n",
       " 'washing_machine',\n",
       " 'clock_tick',\n",
       " 'sneezing',\n",
       " 'rooster',\n",
       " 'sea_waves',\n",
       " 'siren',\n",
       " 'cat',\n",
       " 'door_wood_creaks',\n",
       " 'crickets']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_esc50_labels = esc50_labels['category'].unique().tolist()\n",
    "unique_esc50_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6e22ad1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m esc_similarity_df = \u001b[43mbuild_similarity_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43munique_esc50_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m esc_similarity_df\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mbuild_similarity_dataframe\u001b[39m\u001b[34m(query_labels, dataset_labels, top_k)\u001b[39m\n\u001b[32m     23\u001b[39m mapping_data = []\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ontology_label \u001b[38;5;129;01min\u001b[39;00m query_labels:\n\u001b[32m     26\u001b[39m     \u001b[38;5;66;03m# Embed and normalize the ontology label\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     query_vector = \u001b[43membed_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43montology_label\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# Search for top-k similar dataset labels\u001b[39;00m\n\u001b[32m     30\u001b[39m     scores, indices = index.search(query_vector, top_k)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36membed_texts\u001b[39m\u001b[34m(texts)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_texts\u001b[39m(texts)-> np.ndarray:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     vectors = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.astype(\u001b[33m'\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# Normalize the vectors to unit length\u001b[39;00m\n\u001b[32m      8\u001b[39m     vectors = vectors / np.linalg.norm(vectors, axis=\u001b[32m1\u001b[39m, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py:1094\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1091\u001b[39m features.update(extra_features)\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1096\u001b[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py:1175\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m   1169\u001b[39m             module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m   1170\u001b[39m         module_kwargs = {\n\u001b[32m   1171\u001b[39m             key: value\n\u001b[32m   1172\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m   1173\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mforward_kwargs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.forward_kwargs)\n\u001b[32m   1174\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/sentence_transformers/models/Transformer.py:261\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03mForward pass through the transformer model.\u001b[39;00m\n\u001b[32m    240\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m \u001b[33;03m        - 'all_layer_embeddings': If the model outputs hidden states, contains embeddings from all layers\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    259\u001b[39m trans_features = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_forward_params}\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m token_embeddings = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    263\u001b[39m features[\u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m] = token_embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:1064\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1061\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1066\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1067\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1069\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/transformers/models/gemma3/modeling_gemma3.py:570\u001b[39m, in \u001b[36mGemma3TextModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **kwargs)\u001b[39m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    568\u001b[39m     all_hidden_states += (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings_global\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings_global\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings_local\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    583\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/transformers/models/gemma3/modeling_gemma3.py:382\u001b[39m, in \u001b[36mGemma3DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings_global, position_embeddings_local, attention_mask, position_ids, past_key_values, output_attentions, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    380\u001b[39m     position_embeddings = position_embeddings_global\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m hidden_states, self_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    393\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.post_attention_layernorm(hidden_states)\n\u001b[32m    394\u001b[39m hidden_states = residual + hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/transformers/models/gemma3/modeling_gemma3.py:327\u001b[39m, in \u001b[36mGemma3Attention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config._attn_implementation != \u001b[33m\"\u001b[39m\u001b[33meager\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    325\u001b[39m     attention_interface = ALL_ATTENTION_FUNCTIONS[\u001b[38;5;28mself\u001b[39m.config._attn_implementation]\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m attn_output, attn_weights = \u001b[43mattention_interface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention_dropout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m attn_output = attn_output.reshape(*input_shape, -\u001b[32m1\u001b[39m).contiguous()\n\u001b[32m    340\u001b[39m attn_output = \u001b[38;5;28mself\u001b[39m.o_proj(attn_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Thesis/project/code/.venv/lib/python3.13/site-packages/transformers/integrations/sdpa_attention.py:96\u001b[39m, in \u001b[36msdpa_attention_forward\u001b[39m\u001b[34m(module, query, key, value, attention_mask, dropout, scaling, is_causal, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m attention_mask.dtype != torch.bool:\n\u001b[32m     93\u001b[39m         \u001b[38;5;66;03m# Convert to boolean type, making sdpa to force call FlashAttentionScore to improve performance.\u001b[39;00m\n\u001b[32m     94\u001b[39m         attention_mask = torch.logical_not(attention_mask.bool()).to(query.device)\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m attn_output = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msdpa_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m attn_output = attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m).contiguous()\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "esc_similarity_df = build_similarity_dataframe(\n",
    "    query_labels=labels,\n",
    "    dataset_labels=unique_esc50_labels,\n",
    "    top_k=3\n",
    ")\n",
    "esc_similarity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2627416",
   "metadata": {},
   "source": [
    "Now we have all the information needed to count the number of samples in ESC-50 similar to \"plane\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b8e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "esc_similarity_df[esc_similarity_df['ontology_label'] == 'plane']['dataset_labels'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401ee49d",
   "metadata": {},
   "source": [
    "Only \"airplane\" is similar enough to \"plane\" since we already have helicopter and engine in our ontology labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25500549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count 'airplane' occurrences per fold\n",
    "esc50_airplane_counts = esc50_labels[esc50_labels['category'] == 'airplane'].groupby('fold').size().sort_index()\n",
    "esc50_airplane_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6260d6c3",
   "metadata": {},
   "source": [
    "Unique airplane samples in ESC-50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd5dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All unique airplane recordings in ESC-50\n",
    "airplane_rows = esc50_labels[esc50_labels['category'] == 'airplane']\n",
    "unique_airplane_filenames = airplane_rows['filename'].unique()\n",
    "len(unique_airplane_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f19c0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all overlapping airplane samples\n",
    "esc50_labels[esc50_labels[\"category\"] == \"airplane\"].shape[0] - len(unique_airplane_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca79d8c5",
   "metadata": {},
   "source": [
    "### FSD50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac0ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsd_vocab_labels = pd.read_csv(\"../../data/metadata/fsd50k_labels/vocabulary.csv\",header =None,names =['label','mid'])\n",
    "fsd_vocab_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc683f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsd_similarity_df = build_similarity_dataframe(\n",
    "    query_labels=labels,\n",
    "    dataset_labels=fsd_vocab_labels['label'].tolist(),\n",
    "    top_k=3\n",
    ")\n",
    "fsd_similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce3a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_labels = fsd_similarity_df[fsd_similarity_df['ontology_label'] == 'plane']['dataset_labels'].values[0][0:2]\n",
    "plane_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a519d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat train and eval labels\n",
    "fsd_labels_train = pd.read_csv(\"../../data/metadata/fsd50k_labels/dev.csv\")\n",
    "fsd_labels_dev = pd.read_csv(\"../../data/metadata/fsd50k_labels/eval.csv\")\n",
    "fsd_labels = pd.concat([fsd_labels_train.assign(split=\"train\"), fsd_labels_dev.assign(split=\"eval\")], ignore_index=True)\n",
    "fsd_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39211b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count 'plane' occurrences in FSD50K by split when any label matches plane_labels\n",
    "plane_set = set(plane_labels)\n",
    "fsd_labels['is_plane'] = fsd_labels['labels'].str.split(',').apply(lambda labs: any(l in plane_set for l in labs))\n",
    "\n",
    "plane_counts_fsd = fsd_labels[fsd_labels['is_plane']].groupby('split').size().sort_index()\n",
    "plane_counts_fsd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d30ac5e",
   "metadata": {},
   "source": [
    "### Captdure (captioned sounds dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8fe562",
   "metadata": {},
   "source": [
    "(No planes, single sound sources mostly indoor sounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c26b71c",
   "metadata": {},
   "source": [
    "### Sounddesc (captioned sounds dataset bbc sound effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf7982",
   "metadata": {},
   "outputs": [],
   "source": [
    "sounddescs_categories = pd.read_pickle(\"../../data/metadata/sounddesc/sounddescs_categories.pkl\")\n",
    "sounddescs_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b80b31f",
   "metadata": {},
   "source": [
    "Captions for later, specifically for clap embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6be82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sounddescs_descriptions = pd.read_pickle(\"../../data/metadata/sounddesc/sounddescs_descriptions.pkl\")\n",
    "sounddescs_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900297ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all unique categories found in values of the dictionary\n",
    "unique_sounddesc = list(set([item for sublist in sounddescs_categories.values() for item in sublist]))\n",
    "\n",
    "\n",
    "sounddescs_similarity_df = build_similarity_dataframe(\n",
    "    query_labels=labels,\n",
    "    dataset_labels=unique_sounddesc,\n",
    "    top_k=3\n",
    ")\n",
    "sounddescs_similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf85594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity for 'plane'\n",
    "sounddescs_similarity_df[sounddescs_similarity_df['ontology_label'] == 'plane']['dataset_labels'].values[0]\n",
    "# only first one is really relevant: \"Aircraft\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d43d649",
   "metadata": {},
   "source": [
    "Count number of samples similar to \"Aircraft\" in Sounddescs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a6c3d",
   "metadata": {},
   "source": [
    "Load in the sounddesc cleaned/grouped splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4facd213",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sounddesc_split = pd.DataFrame()\n",
    "with open(\"./metadata/splits_sounddesc/group_filtered_split01/test_list.txt\") as f:\n",
    "    test_list = f.read().splitlines()\n",
    "    grouped_sounddesc_split = pd.DataFrame({\n",
    "        'filename': test_list,\n",
    "        'split': 'test'\n",
    "    })\n",
    "\n",
    "with open(\"./metadata/splits_sounddesc/group_filtered_split01/train_list.txt\") as f:\n",
    "    train_list = f.read().splitlines()\n",
    "    train_df = pd.DataFrame({\n",
    "        'filename': train_list,\n",
    "        'split': 'train'\n",
    "    })\n",
    "    grouped_sounddesc_split = pd.concat([grouped_sounddesc_split, train_df], ignore_index=True)\n",
    "\n",
    "with open(\"./metadata/splits_sounddesc/group_filtered_split01/val_list.txt\") as f:\n",
    "    val_list = f.read().splitlines()\n",
    "    val_df = pd.DataFrame({\n",
    "        'filename': val_list,\n",
    "        'split': 'val'\n",
    "    })\n",
    "    grouped_sounddesc_split = pd.concat([grouped_sounddesc_split, val_df], ignore_index=True)\n",
    "\n",
    "grouped_sounddesc_split.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f73da96",
   "metadata": {},
   "source": [
    "attach the categories to the filenames in the proper grouped split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e3fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sounddesc_split['categories'] = grouped_sounddesc_split['filename'].map(sounddescs_categories)\n",
    "grouped_sounddesc_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f285ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of samples that has \"Aircraft\" as their category grouped by split\n",
    "\n",
    "aircraft_counts = grouped_sounddesc_split.explode('categories')\n",
    "aircraft_counts = aircraft_counts[aircraft_counts['categories'] == 'Aircraft']\n",
    "aircraft_counts = aircraft_counts.groupby('split').size().sort_index()\n",
    "aircraft_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e88bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Collect data from each dataset with consistent train/test splits\n",
    "\n",
    "# AudioSet - combine 'eval' into 'test'\n",
    "audioset_plane_df = strong_audioset_labels[strong_audioset_labels[\"label\"].isin(planes)]\n",
    "audioset_split_mapping = {'train': 'train', 'eval': 'test'}\n",
    "audioset_plane_df['unified_split'] = audioset_plane_df['split'].map(audioset_split_mapping)\n",
    "audioset_counts = audioset_plane_df.groupby(\"unified_split\").size().to_dict()\n",
    "\n",
    "# ESC-50 - folds 1-4 as train, fold 5 as test\n",
    "esc50_airplane_df = esc50_labels[esc50_labels['category'] == 'airplane'].copy()\n",
    "esc50_airplane_df['unified_split'] = esc50_airplane_df['fold'].apply(lambda x: 'train' if x <= 4 else 'test')\n",
    "esc50_counts = esc50_airplane_df.groupby('unified_split').size().to_dict()\n",
    "\n",
    "# FSD50K - 'eval' becomes 'test', 'train' stays 'train'\n",
    "fsd_plane_df = fsd_labels[fsd_labels['is_plane']].copy()\n",
    "fsd_split_mapping = {'train': 'train', 'eval': 'test'}\n",
    "fsd_plane_df['unified_split'] = fsd_plane_df['split'].map(fsd_split_mapping)\n",
    "fsd_plane_counts = fsd_plane_df.groupby('unified_split').size().to_dict()\n",
    "\n",
    "# SoundDescs - combine 'val' with 'train', 'test' stays 'test'\n",
    "sounddesc_aircraft_df = grouped_sounddesc_split.explode('categories')\n",
    "sounddesc_aircraft_df = sounddesc_aircraft_df[sounddesc_aircraft_df['categories'] == 'Aircraft'].copy()\n",
    "sounddesc_split_mapping = {'train': 'train', 'val': 'train', 'test': 'test'}\n",
    "sounddesc_aircraft_df['unified_split'] = sounddesc_aircraft_df['split'].map(sounddesc_split_mapping)\n",
    "sounddesc_counts = sounddesc_aircraft_df.groupby('unified_split').size().to_dict()\n",
    "\n",
    "# Create individual bar charts for each dataset\n",
    "fig_audioset = px.bar(\n",
    "    x=list(audioset_counts.keys()),\n",
    "    y=list(audioset_counts.values()),\n",
    "    title=\"AudioSet - Airplane Samples by Split\",\n",
    "    labels={\"x\": \"Split\", \"y\": \"Count\"},\n",
    "    text=list(audioset_counts.values()),\n",
    ")\n",
    "fig_audioset.update_traces(textposition=\"inside\", textangle=0)\n",
    "fig_audioset.update_layout(width=600, height=500)\n",
    "fig_audioset.show()\n",
    "\n",
    "# ESC-50\n",
    "fig_esc50 = px.bar(\n",
    "    x=list(esc50_counts.keys()),\n",
    "    y=list(esc50_counts.values()),\n",
    "    title=\"ESC-50 - Airplane Samples by Split\",\n",
    "    labels={\"x\": \"Split\", \"y\": \"Count\"},\n",
    "    text=list(esc50_counts.values()),\n",
    ")\n",
    "fig_esc50.update_layout(width=600, height=500)\n",
    "fig_esc50.update_traces(textposition=\"inside\", textangle=0)\n",
    "fig_esc50.show()\n",
    "\n",
    "# FSD50K\n",
    "fig_fsd = px.bar(\n",
    "    x=list(fsd_plane_counts.keys()),\n",
    "    y=list(fsd_plane_counts.values()),\n",
    "    title=\"FSD50K - Airplane Samples by Split\",\n",
    "    labels={\"x\": \"Split\", \"y\": \"Count\"},\n",
    "    text=list(fsd_plane_counts.values()),\n",
    ")\n",
    "fig_fsd.update_traces(textposition=\"inside\", textangle=0)\n",
    "fig_fsd.update_layout(width=600, height=500)\n",
    "fig_fsd.show()\n",
    "\n",
    "# SoundDescs\n",
    "fig_sounddesc = px.bar(\n",
    "    x=list(sounddesc_counts.keys()),\n",
    "    y=list(sounddesc_counts.values()),\n",
    "    title=\"SoundDescs - Aircraft Samples by Split\",\n",
    "    labels={\"x\": \"Split\", \"y\": \"Count\"},\n",
    "    text=list(sounddesc_counts.values()),\n",
    ")\n",
    "fig_sounddesc.update_traces(textposition=\"inside\", textangle=0)\n",
    "fig_sounddesc.update_layout(width=600, height=500)\n",
    "fig_sounddesc.show()\n",
    "\n",
    "# Combined comparison - Total samples per dataset\n",
    "total_samples = {\n",
    "    \"AudioSet\": sum(audioset_counts.values()),\n",
    "    \"ESC-50\": sum(esc50_counts.values()),\n",
    "    \"FSD50K\": sum(fsd_plane_counts.values()),\n",
    "    \"SoundDescs\": sum(sounddesc_counts.values()),\n",
    "}\n",
    "\n",
    "fig_total = px.bar(\n",
    "    x=list(total_samples.keys()),\n",
    "    y=list(total_samples.values()),\n",
    "    title=\"Total Airplane/Aircraft Samples Across All Datasets\",\n",
    "    labels={\"x\": \"Dataset\", \"y\": \"Total Count\"},\n",
    "    text=list(total_samples.values()),\n",
    "    color=list(total_samples.keys()),\n",
    ")\n",
    "fig_total.update_traces(textposition=\"inside\", textangle=0)\n",
    "fig_total.update_layout(showlegend=False, width=600, height=500)\n",
    "fig_total.show()\n",
    "\n",
    "# Grand total\n",
    "grand_total = sum(total_samples.values())\n",
    "print(f\"\\nGrand Total Airplane Samples: {grand_total}\")\n",
    "\n",
    "# Create a stacked bar chart showing splits across datasets\n",
    "split_data = []\n",
    "for dataset, counts_dict in [\n",
    "    (\"AudioSet\", audioset_counts),\n",
    "    (\"ESC-50\", esc50_counts),\n",
    "    (\"FSD50K\", fsd_plane_counts),\n",
    "    (\"SoundDescs\", sounddesc_counts),\n",
    "]:\n",
    "    for split, count in counts_dict.items():\n",
    "        split_data.append({\"Dataset\": dataset, \"Split\": split, \"Count\": count})\n",
    "\n",
    "split_df = pd.DataFrame(split_data)\n",
    "\n",
    "fig_stacked = px.bar(\n",
    "    split_df,\n",
    "    x=\"Dataset\",\n",
    "    y=\"Count\",\n",
    "    color=\"Split\",\n",
    "    title=\"Airplane Samples Distribution by Dataset and Split\",\n",
    "    barmode=\"stack\",\n",
    "    text=\"Count\",\n",
    ")\n",
    "fig_stacked.update_traces(textposition=\"inside\", textangle=0)\n",
    "fig_stacked.update_layout(width=500, height=600)\n",
    "fig_stacked.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pie chart showing overall train/test distribution across all datasets\n",
    "overall_train = sum([counts_dict.get('train', 0) for counts_dict in [audioset_counts, esc50_counts, fsd_plane_counts, sounddesc_counts]])\n",
    "overall_test = sum([counts_dict.get('test', 0) for counts_dict in [audioset_counts, esc50_counts, fsd_plane_counts, sounddesc_counts]])\n",
    "\n",
    "fig_pie = go.Figure(data=[go.Pie(\n",
    "    labels=['Train', 'Test'],\n",
    "    values=[overall_train, overall_test],\n",
    "    text=[overall_train, overall_test],\n",
    "    textposition='inside',\n",
    "    textinfo='label+value+percent',\n",
    "    marker=dict(colors=['#636EFA', '#EF553B'])\n",
    ")])\n",
    "\n",
    "fig_pie.update_layout(\n",
    "    title=\"Overall Train/Test Distribution Across All Datasets\",\n",
    "    width=600,\n",
    "    height=500\n",
    ")\n",
    "fig_pie.show()\n",
    "\n",
    "print(f\"\\nTotal Train Samples: {overall_train}\")\n",
    "print(f\"Total Test Samples: {overall_test}\")\n",
    "print(f\"Train/Test Ratio: {overall_train/overall_test:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044c3522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anthropogenic-noise-detection-py3.13 (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
