{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9450b809",
   "metadata": {},
   "source": [
    "# Label counting to determine dataset size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a537f1ec",
   "metadata": {},
   "source": [
    "## Label mapping from ontology to datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78b50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "# from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10336def",
   "metadata": {},
   "source": [
    "Setting up embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d7ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SentenceTransformer(\"google/embeddinggemma-300m\")\n",
    "\n",
    "from transformers import ClapTextModelWithProjection, AutoTokenizer\n",
    "\n",
    "# Text encoder only: ~110M params = ~220MB in float16\n",
    "model = ClapTextModelWithProjection.from_pretrained(\n",
    "    \"laion/clap-htsat-unfused\", dtype=\"float16\"  # Uses ~220MB RAM\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def embed_texts(texts)-> np.ndarray:\n",
    "    # vectors = model.encode(\n",
    "    #     texts, normalize_embeddings=False\n",
    "    # ).astype('float32')\n",
    "    # # Normalize the vectors to unit length\n",
    "    # vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    vectors = model(**inputs).text_embeds.detach().cpu().numpy()\n",
    "    # Normalize the vectors to unit length\n",
    "    vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "    \n",
    "    return vectors\n",
    "\n",
    "def build_index(texts: list[str]) -> faiss.IndexFlatIP:\n",
    "    vectors = embed_texts(texts)\n",
    "    dimension = vectors.shape[1]\n",
    "    \n",
    "    index = faiss.IndexFlatIP(dimension)#\n",
    "    \n",
    "    label_vectors = vectors.astype('float32')\n",
    "    index.add(label_vectors)\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f67fc1",
   "metadata": {},
   "source": [
    "Load in ontology labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625bd2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.namespace import OWL, RDFS\n",
    "import rdflib\n",
    "\n",
    "g = rdflib.Graph()\n",
    "g.parse(\"../../anthropogenic_ontology.ttl\", format=\"turtle\")\n",
    "\n",
    "BASE = (\"http://www.semanticweb.org/dbotteld/ontologies/2025/6/sound_ontology#\")\n",
    "\n",
    "labels = []\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT ?cls ?label\n",
    "WHERE {\n",
    "  ?cls a owl:Class .\n",
    "  FILTER NOT EXISTS { ?sub rdfs:subClassOf ?cls . }\n",
    "  OPTIONAL { ?cls rdfs:label ?label . }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "no_label_list = [\"AudioSet\"]\n",
    "\n",
    "for row in g.query(query, initNs={\"owl\": OWL, \"rdfs\": RDFS, \"base\": BASE}):\n",
    "    label = row.label if row.label else row.cls\n",
    "    if str(label) not in no_label_list:  \n",
    "      labels.append(str(label))\n",
    "\n",
    "label_vectors = embed_texts(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca7983",
   "metadata": {},
   "source": [
    "### Similarity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3b40cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_dataframe(\n",
    "    query_labels: list[str],\n",
    "    dataset_labels: list[str],\n",
    "    top_k: int = 3\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a DataFrame with similarity scores between ontology labels and dataset labels.\n",
    "    \n",
    "    Args:\n",
    "        query_labels: List of ontology labels to query\n",
    "        dataset_labels: List of dataset labels to build the index from\n",
    "        top_k: Number of top similar labels to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: ontology_label, dataset_labels, dataset_indices, similarity_scores\n",
    "    \"\"\"\n",
    "    # Build index from dataset labels\n",
    "    dataset_vectors = embed_texts(dataset_labels)\n",
    "    dimension = dataset_vectors.shape[1]\n",
    "    index = faiss.IndexFlatIP(dimension)\n",
    "    index.add(dataset_vectors)\n",
    "    \n",
    "    mapping_data = []\n",
    "    \n",
    "    for ontology_label in query_labels:\n",
    "        # Embed and normalize the ontology label\n",
    "        query_vector = embed_texts([ontology_label])\n",
    "        \n",
    "        # Search for top-k similar dataset labels\n",
    "        scores, indices = index.search(query_vector, top_k)\n",
    "        \n",
    "        # Get matched labels and round scores\n",
    "        matched_labels = [dataset_labels[i] for i in indices[0]]\n",
    "        rounded_scores = [float(round(float(score), 4)) for score in scores[0]]\n",
    "        \n",
    "        mapping_data.append({\n",
    "            'ontology_label': ontology_label,\n",
    "            'dataset_labels': matched_labels,\n",
    "            'dataset_indices': indices.tolist()[0],\n",
    "            'similarity_scores': rounded_scores\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(mapping_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cfa031",
   "metadata": {},
   "source": [
    "## Class of interest 1: Plane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f346f8c7",
   "metadata": {},
   "source": [
    "### audioset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904b6c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_to_label_map = pd.read_csv(\n",
    "    \"../../data/metadata/audioset/mid_to_display_name.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"mid\", \"display_name\"],\n",
    ")\n",
    "mid_to_label_dict = dict(zip(mid_to_label_map[\"mid\"], mid_to_label_map[\"display_name\"]))\n",
    "\n",
    "mid_to_label_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402e3c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "audioset_labels = pd.read_csv(\n",
    "    \"../../data/metadata/audioset/audioset_train_strong.tsv\", sep=\"\\t\"\n",
    ")\n",
    "audioset_labels['label'] = audioset_labels['label'].apply(lambda x: mid_to_label_dict[x])\n",
    "audioset_labels.head()\n",
    "audioset_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe48a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "audioset_label_list = audioset_labels['label'].unique().tolist()\n",
    "\n",
    "similarity_df = build_similarity_dataframe(\n",
    "    query_labels=labels,\n",
    "    dataset_labels=audioset_label_list,\n",
    "    top_k=6\n",
    ")\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a605720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all audioset labels found for similarity_df\n",
    "all_found_labels = set()\n",
    "for label in similarity_df['dataset_labels']:\n",
    "    all_found_labels.update(label)\n",
    "list(all_found_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340c60c3",
   "metadata": {},
   "source": [
    "#### count all labels similar to \"Plane\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54fd872",
   "metadata": {},
   "source": [
    "Labels most similar to \"plane\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6470ea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "planes = similarity_df[similarity_df['ontology_label'] == 'plane']['dataset_labels'].values[0]\n",
    "planes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb2dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_audioset_labels_train = pd.read_csv(\"../../data/metadata/audioset/audioset_train_strong.tsv\", sep=\"\\t\",header=None,names=[\"filename\", \"start_time\", \"end_time\", \"label\",\"split\", \"caption\"])\n",
    "strong_audioset_labels_eval = pd.read_csv(\"../../data/metadata/audioset/audioset_eval_strong.tsv\", sep=\"\\t\",header=None,names=[\"filename\", \"start_time\", \"end_time\", \"label\", \"split\", \"caption\"])\n",
    "\n",
    "# Merge the two dataframes into one, keeping source split info and resetting the index\n",
    "strong_audioset_labels = pd.concat(\n",
    "    [\n",
    "        strong_audioset_labels_train.assign(split=\"train\"),\n",
    "        strong_audioset_labels_eval.assign(split=\"eval\"),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# quick check\n",
    "strong_audioset_labels.shape, strong_audioset_labels.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the MID codes in 'label' with display names, keeping original MID if no mapping exists\n",
    "strong_audioset_labels['label'] = strong_audioset_labels['label'].map(mid_to_label_dict).fillna(strong_audioset_labels['label'])\n",
    "strong_audioset_labels.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b059a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count exact matches for each plane-related label\n",
    "plane_counts = strong_audioset_labels['label'].isin(planes).value_counts().to_dict()\n",
    "print(plane_counts)\n",
    "\n",
    "# Also show counts broken down by split (train / eval)\n",
    "strong_audioset_labels[strong_audioset_labels['label'].isin(planes)].groupby(['label', 'split']).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf075a6",
   "metadata": {},
   "source": [
    "### urban_sound_8k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3631c0",
   "metadata": {},
   "source": [
    "(no airplane sounds in this dataset, contains only 10 classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c4b89a",
   "metadata": {},
   "source": [
    "### Esc-50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d7563d",
   "metadata": {},
   "source": [
    "Load in labels from ESC-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc2b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "esc50_labels = pd.read_csv(\"../../data/metadata/esc50/esc50.csv\")\n",
    "esc50_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1530816",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_esc50_labels = esc50_labels['category'].unique().tolist()\n",
    "unique_esc50_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e22ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "esc_similarity_df = build_similarity_dataframe(\n",
    "    query_labels=labels,\n",
    "    dataset_labels=unique_esc50_labels,\n",
    "    top_k=6\n",
    ")\n",
    "esc_similarity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2627416",
   "metadata": {},
   "source": [
    "Now we have all the information needed to count the number of samples in ESC-50 similar to \"plane\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b8e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "esc_similarity_df[esc_similarity_df['ontology_label'] == 'plane']['dataset_labels'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401ee49d",
   "metadata": {},
   "source": [
    "Only \"airplane\" is similar enough to \"plane\" since we already have helicopter and engine in our ontology labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25500549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count 'airplane' occurrences per fold\n",
    "esc50_airplane_counts = esc50_labels[esc50_labels['category'] == 'airplane'].groupby('fold').size().sort_index()\n",
    "esc50_airplane_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6260d6c3",
   "metadata": {},
   "source": [
    "Unique airplane samples in ESC-50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd5dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All unique airplane recordings in ESC-50\n",
    "airplane_rows = esc50_labels[esc50_labels['category'] == 'airplane']\n",
    "unique_airplane_filenames = airplane_rows['filename'].unique()\n",
    "len(unique_airplane_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f19c0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all overlapping airplane samples\n",
    "esc50_labels[esc50_labels[\"category\"] == \"airplane\"].shape[0] - len(unique_airplane_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca79d8c5",
   "metadata": {},
   "source": [
    "### FSD50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac0ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsd_vocab_labels = pd.read_csv(\"../../data/metadata/fsd50k_labels/vocabulary.csv\",header =None,names =['label','mid'])\n",
    "fsd_vocab_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc683f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsd_similarity_df = build_similarity_dataframe(\n",
    "    query_labels=labels,\n",
    "    dataset_labels=fsd_vocab_labels['label'].tolist(),\n",
    "    top_k=6\n",
    ")\n",
    "fsd_similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce3a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_labels = fsd_similarity_df[fsd_similarity_df['ontology_label'] == 'plane']['dataset_labels'].values[0][0:2]\n",
    "plane_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a519d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat train and eval labels\n",
    "fsd_labels_train = pd.read_csv(\"../../data/metadata/fsd50k_labels/dev.csv\")\n",
    "fsd_labels_dev = pd.read_csv(\"../../data/metadata/fsd50k_labels/eval.csv\")\n",
    "fsd_labels = pd.concat([fsd_labels_train.assign(split=\"train\"), fsd_labels_dev.assign(split=\"eval\")], ignore_index=True)\n",
    "fsd_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39211b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count 'plane' occurrences in FSD50K by split when any label matches plane_labels\n",
    "plane_set = set(plane_labels)\n",
    "fsd_labels['is_plane'] = fsd_labels['labels'].str.split(',').apply(lambda labs: any(l in plane_set for l in labs))\n",
    "\n",
    "plane_counts_fsd = fsd_labels[fsd_labels['is_plane']].groupby('split').size().sort_index()\n",
    "plane_counts_fsd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d30ac5e",
   "metadata": {},
   "source": [
    "### Captdure (captioned sounds dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8fe562",
   "metadata": {},
   "source": [
    "(No planes, single sound sources mostly indoor sounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c26b71c",
   "metadata": {},
   "source": [
    "### Sounddesc (captioned sounds dataset bbc sound effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf7982",
   "metadata": {},
   "outputs": [],
   "source": [
    "sounddescs_categories = pd.read_pickle(\"../../data/metadata/sounddesc/sounddescs_categories.pkl\")\n",
    "sounddescs_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b80b31f",
   "metadata": {},
   "source": [
    "Captions for later, specifically for clap embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6be82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sounddescs_descriptions = pd.read_pickle(\"../../data/metadata/sounddesc/sounddescs_descriptions.pkl\")\n",
    "sounddescs_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900297ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all unique categories found in values of the dictionary\n",
    "unique_sounddesc = list(set([item for sublist in sounddescs_categories.values() for item in sublist]))\n",
    "\n",
    "\n",
    "sounddescs_similarity_df = build_similarity_dataframe(\n",
    "    query_labels=labels,\n",
    "    dataset_labels=unique_sounddesc,\n",
    "    top_k=6\n",
    ")\n",
    "sounddescs_similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf85594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity for 'plane'\n",
    "sounddescs_similarity_df[sounddescs_similarity_df['ontology_label'] == 'plane']['dataset_labels'].values[0]\n",
    "# only first one is really relevant: \"Aircraft\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d43d649",
   "metadata": {},
   "source": [
    "Count number of samples similar to \"Aircraft\" in Sounddescs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a6c3d",
   "metadata": {},
   "source": [
    "Load in the sounddesc cleaned/grouped splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4facd213",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sounddesc_split = pd.DataFrame()\n",
    "with open(\"./metadata/splits_sounddesc/group_filtered_split01/test_list.txt\") as f:\n",
    "    test_list = f.read().splitlines()\n",
    "    grouped_sounddesc_split = pd.DataFrame({\n",
    "        'filename': test_list,\n",
    "        'split': 'test'\n",
    "    })\n",
    "\n",
    "with open(\"./metadata/splits_sounddesc/group_filtered_split01/train_list.txt\") as f:\n",
    "    train_list = f.read().splitlines()\n",
    "    train_df = pd.DataFrame({\n",
    "        'filename': train_list,\n",
    "        'split': 'train'\n",
    "    })\n",
    "    grouped_sounddesc_split = pd.concat([grouped_sounddesc_split, train_df], ignore_index=True)\n",
    "\n",
    "with open(\"./metadata/splits_sounddesc/group_filtered_split01/val_list.txt\") as f:\n",
    "    val_list = f.read().splitlines()\n",
    "    val_df = pd.DataFrame({\n",
    "        'filename': val_list,\n",
    "        'split': 'val'\n",
    "    })\n",
    "    grouped_sounddesc_split = pd.concat([grouped_sounddesc_split, val_df], ignore_index=True)\n",
    "\n",
    "grouped_sounddesc_split.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f73da96",
   "metadata": {},
   "source": [
    "attach the categories to the filenames in the proper grouped split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e3fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sounddesc_split['categories'] = grouped_sounddesc_split['filename'].map(sounddescs_categories)\n",
    "grouped_sounddesc_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f285ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of samples that has \"Aircraft\" as their category grouped by split\n",
    "\n",
    "aircraft_counts = grouped_sounddesc_split.explode('categories')\n",
    "aircraft_counts = aircraft_counts[aircraft_counts['categories'] == 'Aircraft']\n",
    "aircraft_counts = aircraft_counts.groupby('split').size().sort_index()\n",
    "aircraft_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e88bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Collect data from each dataset with consistent train/test splits\n",
    "\n",
    "# AudioSet - combine 'eval' into 'test'\n",
    "audioset_plane_df = strong_audioset_labels[strong_audioset_labels[\"label\"].isin(planes)]\n",
    "audioset_split_mapping = {'train': 'train', 'eval': 'test'}\n",
    "audioset_plane_df['unified_split'] = audioset_plane_df['split'].map(audioset_split_mapping)\n",
    "audioset_counts = audioset_plane_df.groupby(\"unified_split\").size().to_dict()\n",
    "\n",
    "# ESC-50 - folds 1-4 as train, fold 5 as test\n",
    "esc50_airplane_df = esc50_labels[esc50_labels['category'] == 'airplane'].copy()\n",
    "esc50_airplane_df['unified_split'] = esc50_airplane_df['fold'].apply(lambda x: 'train' if x <= 4 else 'test')\n",
    "esc50_counts = esc50_airplane_df.groupby('unified_split').size().to_dict()\n",
    "\n",
    "# FSD50K - 'eval' becomes 'test', 'train' stays 'train'\n",
    "fsd_plane_df = fsd_labels[fsd_labels['is_plane']].copy()\n",
    "fsd_split_mapping = {'train': 'train', 'eval': 'test'}\n",
    "fsd_plane_df['unified_split'] = fsd_plane_df['split'].map(fsd_split_mapping)\n",
    "fsd_plane_counts = fsd_plane_df.groupby('unified_split').size().to_dict()\n",
    "\n",
    "# SoundDescs - combine 'val' with 'train', 'test' stays 'test'\n",
    "sounddesc_aircraft_df = grouped_sounddesc_split.explode('categories')\n",
    "sounddesc_aircraft_df = sounddesc_aircraft_df[sounddesc_aircraft_df['categories'] == 'Aircraft'].copy()\n",
    "sounddesc_split_mapping = {'train': 'train', 'val': 'train', 'test': 'test'}\n",
    "sounddesc_aircraft_df['unified_split'] = sounddesc_aircraft_df['split'].map(sounddesc_split_mapping)\n",
    "sounddesc_counts = sounddesc_aircraft_df.groupby('unified_split').size().to_dict()\n",
    "\n",
    "# Create individual bar charts for each dataset\n",
    "fig_audioset = px.bar(\n",
    "    x=list(audioset_counts.keys()),\n",
    "    y=list(audioset_counts.values()),\n",
    "    title=\"AudioSet - Airplane Samples by Split\",\n",
    "    labels={\"x\": \"Split\", \"y\": \"Count\"},\n",
    "    text=list(audioset_counts.values()),\n",
    ")\n",
    "fig_audioset.update_traces(textposition=\"inside\", textangle=0)\n",
    "fig_audioset.update_layout(width=600, height=500)\n",
    "fig_audioset.show()\n",
    "\n",
    "# ESC-50\n",
    "fig_esc50 = px.bar(\n",
    "    x=list(esc50_counts.keys()),\n",
    "    y=list(esc50_counts.values()),\n",
    "    title=\"ESC-50 - Airplane Samples by Split\",\n",
    "    labels={\"x\": \"Split\", \"y\": \"Count\"},\n",
    "    text=list(esc50_counts.values()),\n",
    ")\n",
    "fig_esc50.update_layout(width=600, height=500)\n",
    "fig_esc50.update_traces(textposition=\"inside\", textangle=0)\n",
    "fig_esc50.show()\n",
    "\n",
    "# FSD50K\n",
    "fig_fsd = px.bar(\n",
    "    x=list(fsd_plane_counts.keys()),\n",
    "    y=list(fsd_plane_counts.values()),\n",
    "    title=\"FSD50K - Airplane Samples by Split\",\n",
    "    labels={\"x\": \"Split\", \"y\": \"Count\"},\n",
    "    text=list(fsd_plane_counts.values()),\n",
    ")\n",
    "fig_fsd.update_traces(textposition=\"inside\", textangle=0)\n",
    "fig_fsd.update_layout(width=600, height=500)\n",
    "fig_fsd.show()\n",
    "\n",
    "# SoundDescs\n",
    "fig_sounddesc = px.bar(\n",
    "    x=list(sounddesc_counts.keys()),\n",
    "    y=list(sounddesc_counts.values()),\n",
    "    title=\"SoundDescs - Aircraft Samples by Split\",\n",
    "    labels={\"x\": \"Split\", \"y\": \"Count\"},\n",
    "    text=list(sounddesc_counts.values()),\n",
    ")\n",
    "fig_sounddesc.update_traces(textposition=\"inside\", textangle=0)\n",
    "fig_sounddesc.update_layout(width=600, height=500)\n",
    "fig_sounddesc.show()\n",
    "\n",
    "# Combined comparison - Total samples per dataset\n",
    "total_samples = {\n",
    "    \"AudioSet\": sum(audioset_counts.values()),\n",
    "    \"ESC-50\": sum(esc50_counts.values()),\n",
    "    \"FSD50K\": sum(fsd_plane_counts.values()),\n",
    "    \"SoundDescs\": sum(sounddesc_counts.values()),\n",
    "}\n",
    "\n",
    "fig_total = px.bar(\n",
    "    x=list(total_samples.keys()),\n",
    "    y=list(total_samples.values()),\n",
    "    title=\"Total Airplane/Aircraft Samples Across All Datasets\",\n",
    "    labels={\"x\": \"Dataset\", \"y\": \"Total Count\"},\n",
    "    text=list(total_samples.values()),\n",
    "    color=list(total_samples.keys()),\n",
    ")\n",
    "fig_total.update_traces(textposition=\"inside\", textangle=0)\n",
    "fig_total.update_layout(showlegend=False, width=600, height=500)\n",
    "fig_total.show()\n",
    "\n",
    "# Grand total\n",
    "grand_total = sum(total_samples.values())\n",
    "print(f\"\\nGrand Total Airplane Samples: {grand_total}\")\n",
    "\n",
    "# Create a stacked bar chart showing splits across datasets\n",
    "split_data = []\n",
    "for dataset, counts_dict in [\n",
    "    (\"AudioSet\", audioset_counts),\n",
    "    (\"ESC-50\", esc50_counts),\n",
    "    (\"FSD50K\", fsd_plane_counts),\n",
    "    (\"SoundDescs\", sounddesc_counts),\n",
    "]:\n",
    "    for split, count in counts_dict.items():\n",
    "        split_data.append({\"Dataset\": dataset, \"Split\": split, \"Count\": count})\n",
    "\n",
    "split_df = pd.DataFrame(split_data)\n",
    "\n",
    "fig_stacked = px.bar(\n",
    "    split_df,\n",
    "    x=\"Dataset\",\n",
    "    y=\"Count\",\n",
    "    color=\"Split\",\n",
    "    title=\"Airplane Samples Distribution by Dataset and Split\",\n",
    "    barmode=\"stack\",\n",
    "    text=\"Count\",\n",
    ")\n",
    "fig_stacked.update_traces(textposition=\"inside\", textangle=0)\n",
    "fig_stacked.update_layout(width=500, height=600)\n",
    "fig_stacked.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pie chart showing overall train/test distribution across all datasets\n",
    "overall_train = sum([counts_dict.get('train', 0) for counts_dict in [audioset_counts, esc50_counts, fsd_plane_counts, sounddesc_counts]])\n",
    "overall_test = sum([counts_dict.get('test', 0) for counts_dict in [audioset_counts, esc50_counts, fsd_plane_counts, sounddesc_counts]])\n",
    "\n",
    "fig_pie = go.Figure(data=[go.Pie(\n",
    "    labels=['Train', 'Test'],\n",
    "    values=[overall_train, overall_test],\n",
    "    text=[overall_train, overall_test],\n",
    "    textposition='inside',\n",
    "    textinfo='label+value+percent',\n",
    "    marker=dict(colors=['#636EFA', '#EF553B'])\n",
    ")])\n",
    "\n",
    "fig_pie.update_layout(\n",
    "    title=\"Overall Train/Test Distribution Across All Datasets\",\n",
    "    width=600,\n",
    "    height=500\n",
    ")\n",
    "fig_pie.show()\n",
    "\n",
    "print(f\"\\nTotal Train Samples: {overall_train}\")\n",
    "print(f\"Total Test Samples: {overall_test}\")\n",
    "print(f\"Train/Test Ratio: {overall_train/overall_test:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044c3522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a combined mapping DataFrame and create visualizations (heatmap + sankey).\n",
    "# This cell flattens existing similarity DataFrames and draws interactive plots.\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from collections import OrderedDict\n",
    "\n",
    "def flatten_similarity_df(sim_df, dataset_name):\n",
    "    rows = []\n",
    "    for _, r in sim_df.iterrows():\n",
    "        ont = r['ontology_label']\n",
    "        labels = r['dataset_labels']\n",
    "        indices = r['dataset_indices']\n",
    "        scores = r['similarity_scores']\n",
    "        for lbl, idx, score in zip(labels, indices, scores):\n",
    "            rows.append({\n",
    "                'ontology_label': ont,\n",
    "                'dataset_label': lbl,\n",
    "                'dataset_index': int(idx),\n",
    "                'score': float(score),\n",
    "                'dataset': dataset_name\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "dfs = []\n",
    "# AudioSet\n",
    "if 'similarity_df' in globals():\n",
    "    dfs.append(flatten_similarity_df(similarity_df, 'AudioSet'))\n",
    "else:\n",
    "    try:\n",
    "        audioset_label_list\n",
    "    except NameError:\n",
    "        audioset_labels_tmp = pd.read_csv('../../data/metadata/audioset/class_labels_audioset.csv')\n",
    "        audioset_label_list = audioset_labels_tmp['display_name'].unique().tolist()\n",
    "    dfs.append(flatten_similarity_df(build_similarity_dataframe(labels, audioset_label_list, top_k=3), 'AudioSet'))\n",
    "\n",
    "# ESC-50\n",
    "if 'esc_similarity_df' in globals():\n",
    "    dfs.append(flatten_similarity_df(esc_similarity_df, 'ESC-50'))\n",
    "else:\n",
    "    try:\n",
    "        unique_esc50_labels\n",
    "    except NameError:\n",
    "        esc50_tmp = pd.read_csv('../../data/metadata/esc50/esc50.csv')\n",
    "        unique_esc50_labels = esc50_tmp['category'].unique().tolist()\n",
    "    dfs.append(flatten_similarity_df(build_similarity_dataframe(labels, unique_esc50_labels, top_k=3), 'ESC-50'))\n",
    "\n",
    "# FSD50K\n",
    "if 'fsd_similarity_df' in globals():\n",
    "    dfs.append(flatten_similarity_df(fsd_similarity_df, 'FSD50K'))\n",
    "else:\n",
    "    try:\n",
    "        fsd_vocab_labels\n",
    "    except NameError:\n",
    "        fsd_vocab_labels = pd.read_csv('../../data/metadata/fsd50k_labels/vocabulary.csv', header=None, names=['label','mid'])\n",
    "    dfs.append(flatten_similarity_df(build_similarity_dataframe(labels, fsd_vocab_labels['label'].tolist(), top_k=3), 'FSD50K'))\n",
    "\n",
    "# SoundDescs\n",
    "if 'sounddescs_similarity_df' in globals():\n",
    "    dfs.append(flatten_similarity_df(sounddescs_similarity_df, 'SoundDescs'))\n",
    "else:\n",
    "    try:\n",
    "        unique_sounddesc\n",
    "    except NameError:\n",
    "        unique_sounddesc = []\n",
    "    if len(unique_sounddesc) > 0:\n",
    "        dfs.append(flatten_similarity_df(build_similarity_dataframe(labels, unique_sounddesc, top_k=3), 'SoundDescs'))\n",
    "\n",
    "if len(dfs) == 0:\n",
    "    raise RuntimeError('No similarity DataFrames or label lists found. Run the similarity cells first.')\n",
    "\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "combined_df['ontology_label'] = combined_df['ontology_label'].astype(str)\n",
    "\n",
    "# Aggregate duplicates by max score (keeps strongest match per pair)\n",
    "agg_df = combined_df.groupby(['ontology_label','dataset','dataset_label'], as_index=False).agg({'score':'max'})\n",
    "\n",
    "# Heatmap: pivot ontology x dataset_label (shows strongest similarity)\n",
    "heat_pivot = agg_df.pivot_table(index='ontology_label', columns='dataset_label', values='score', aggfunc='max', fill_value=0)\n",
    "if heat_pivot.shape[0] > 0 and heat_pivot.shape[1] > 0:\n",
    "    fig_heat = px.imshow(heat_pivot, labels=dict(x='Dataset Label', y='Ontology Label', color='Similarity'),\n",
    "                     aspect='auto', title='Ontology → Dataset Label Similarity Heatmap')\n",
    "    fig_heat.update_layout(height=800, width=1000)\n",
    "    fig_heat.show()\n",
    "else:\n",
    "    print('Heatmap: no data to display')\n",
    "\n",
    "# Sankey: build nodes and aggregated link values across dataset groups\n",
    "sankey_df = agg_df.copy()\n",
    "# Optionally scale scores so sankey has visible widths\n",
    "sankey_df['value'] = sankey_df['score']\n",
    "\n",
    "ont_nodes = list(OrderedDict.fromkeys(sankey_df['ontology_label'].tolist()))\n",
    "target_nodes = list(OrderedDict.fromkeys((sankey_df['dataset'] + '::' + sankey_df['dataset_label']).tolist()))\n",
    "nodes = ont_nodes + target_nodes\n",
    "node_index = {n:i for i,n in enumerate(nodes)}\n",
    "\n",
    "sources = []\n",
    "targets = []\n",
    "values = []\n",
    "labels = []\n",
    "for _, r in sankey_df.iterrows():\n",
    "    s = node_index[r['ontology_label']]\n",
    "    t = node_index[r['dataset'] + '::' + r['dataset_label']]\n",
    "    sources.append(s)\n",
    "    targets.append(t)\n",
    "    values.append(max(r['value'], 0.0))\n",
    "\n",
    "if len(sources) > 0:\n",
    "    link = dict(source=sources, target=targets, value=values)\n",
    "    fig_sankey = go.Figure(data=[go.Sankey(node=dict(label=nodes, pad=15, thickness=15), link=link)])\n",
    "    fig_sankey.update_layout(title_text='Ontology → Dataset Labels (Sankey)', font_size=10, height=800, width=1200)\n",
    "    fig_sankey.show()\n",
    "else:\n",
    "    print('Sankey: no links to display')\n",
    "\n",
    "# Quick check output\n",
    "print('Saved: ontology_dataset_heatmap.html, ontology_dataset_sankey.html')    \n",
    "fig_sankey.write_image('ontology_dataset_sankey.jpeg')    \n",
    "fig_heat.write_image('ontology_dataset_heatmap.jpeg') # Save interactive HTMLs for sharing (optional)display(agg_df.sort_values(['ontology_label','score'], ascending=[True, False]).head(20))Combined mapping sample:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901ed394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 6 ontology and 6 dataset labels from the full combined_df (cell 58's output) and plot a heatmap for a comprehensive example\n",
    "# Fixes: avoid using list.append()/extend() return values, ensure 'plane' in sampled ontology, and include aircraft-related dataset labels if present\n",
    "import random\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Ensure combined_df exists\n",
    "if 'combined_df' not in globals():\n",
    "    raise RuntimeError('combined_df not found. Run the combined mapping cell first.')\n",
    "\n",
    "df_full = combined_df.copy()\n",
    "\n",
    "# If any AudioSet labels are MIDs, map them to display names using mid_to_label_dict if available and dataset column exists\n",
    "if 'mid_to_label_dict' in globals() and 'dataset' in df_full.columns:\n",
    "    mask = df_full['dataset'] == 'AudioSet'\n",
    "    df_full.loc[mask, 'dataset_label'] = df_full.loc[mask, 'dataset_label'].map(lambda x: mid_to_label_dict.get(x, x))\n",
    "\n",
    "# Get all ontology labels and all unique dataset labels from combined_df\n",
    "all_ontology = df_full['ontology_label'].astype(str).unique().tolist()\n",
    "all_dataset = sorted(df_full['dataset_label'].astype(str).unique().tolist())\n",
    "\n",
    "# Build sampled ontology list: pick up to 5 random and ensure 'plane' is included (if present) to make a 6-item example\n",
    "sample_size = 6\n",
    "if len(all_ontology) <= sample_size:\n",
    "    sampled_ontology = all_ontology.copy()\n",
    "else:\n",
    "    # sample sample_size-1 and reserve one slot for 'plane' if available\n",
    "    sampled_ontology = random.sample(all_ontology, sample_size - 1)\n",
    "    if 'plane' in all_ontology and 'plane' not in sampled_ontology:\n",
    "        sampled_ontology.append('plane')\n",
    "    else:\n",
    "        # if 'plane' not available, fill the last slot from remaining\n",
    "        remaining = [o for o in all_ontology if o not in sampled_ontology]\n",
    "        if remaining:\n",
    "            sampled_ontology.append(random.choice(remaining))\n",
    "\n",
    "# Build sampled dataset list: try to include known aircraft-related labels if present\n",
    "preferred = [\"Aircraft engine\", \"Fixed-wing aircraft, airplane\", \"Aircraft\", \"airplane\"]\n",
    "extras = [p for p in preferred if p in all_dataset]\n",
    "if len(all_dataset) <= sample_size:\n",
    "    sampled_dataset = all_dataset.copy()\n",
    "else:\n",
    "    # choose random labels excluding extras then add extras (up to sample_size)\n",
    "    pool = [d for d in all_dataset if d not in extras]\n",
    "    n_random = max(0, sample_size - len(extras))\n",
    "    sampled_dataset = random.sample(pool, min(n_random, len(pool)))\n",
    "    # add extras while keeping total <= sample_size\n",
    "    for e in extras:\n",
    "        if len(sampled_dataset) < sample_size:\n",
    "            sampled_dataset.append(e)\n",
    "\n",
    "# Final safety: ensure lengths >0\n",
    "if len(sampled_ontology) == 0 or len(sampled_dataset) == 0:\n",
    "    raise RuntimeError('Not enough ontology or dataset labels to sample for example.')\n",
    "\n",
    "# Build a similarity matrix: rows=ontology, cols=dataset label, values=similarity score (max if multiple)\n",
    "sim_matrix = pd.DataFrame(0.0, index=sampled_ontology, columns=sampled_dataset)\n",
    "for _, row in df_full.iterrows():\n",
    "    ont = str(row.get('ontology_label'))\n",
    "    lbl = str(row.get('dataset_label'))\n",
    "    score = float(row.get('score', 0.0))\n",
    "    if ont in sampled_ontology and lbl in sampled_dataset:\n",
    "        sim_matrix.loc[ont, lbl] = max(sim_matrix.loc[ont, lbl], score)\n",
    "\n",
    "fig = px.imshow(\n",
    "    sim_matrix,\n",
    "    text_auto=True,\n",
    "    color_continuous_scale='Blues',\n",
    "    labels=dict(x='Dataset Label', y='Ontology Label', color='Similarity'),\n",
    "    title='Sampled Ontology to Dataset Label Mapping (Comprehensive Example)'\n",
    ")\n",
    "fig.update_layout(width=800, height=520)\n",
    "fig.show()\n",
    "\n",
    "print('Sampled ontology labels:', list(sim_matrix.index))\n",
    "print('Sampled dataset labels:', list(sim_matrix.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c376798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anthropogenic-noise-detection-py3.12 (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
